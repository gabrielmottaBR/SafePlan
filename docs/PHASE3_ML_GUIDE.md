# SafePlan - Fase 3: ML Integration (Machine Learning)

> Integra√ß√£o de Machine Learning para detec√ß√£o de anomalias e forecasting de s√©ries temporais

**Status:** ‚úÖ Implementado

**√öltima Atualiza√ß√£o:** 2026-02-20

---

## üìã √çndice

1. [Vis√£o Geral](#vis√£o-geral)
2. [Componentes Implementados](#componentes-implementados)
3. [Anomaly Detection](#anomaly-detection)
4. [Time Series Forecasting](#time-series-forecasting)
5. [ML Engine](#ml-engine)
6. [Interface Streamlit](#interface-streamlit)
7. [Uso e Exemplos](#uso-e-exemplos)
8. [Testes](#testes)
9. [Troubleshooting](#troubleshooting)

---

## üìä Vis√£o Geral

A Fase 3 introduz capacidades de Machine Learning ao SafePlan:

### **Anomaly Detection** üö®
- Detecta comportamentos anormais em leituras de sensores
- Usa ensemble de algoritmos: Isolation Forest + Local Outlier Factor
- Scores de anomalia normalizados (0-1)

### **Time Series Forecasting** üîÆ
- Prev√™ valores futuros de sensores
- Baseado em Facebook Prophet
- Intervalos de confian√ßa configur√°veis
- Detec√ß√£o autom√°tica de tend√™ncias e sazonalidade

### **ML Engine** üîß
- Orquestra opera√ß√µes de ML
- Gerencia m√∫ltiplos modelos por sensor
- Persiste predi√ß√µes em banco de dados
- Monitoramento de qualidade dos modelos

---

## üì¶ Componentes Implementados

### Backend

#### 1. **Anomaly Detector** (`src/ml/anomaly_detector.py`)

Detecta anomalias usando dois algoritmos:

**Isolation Forest**
- Isola pontos an√¥malos partir de isolamento
- Eficiente para dados altos-dimensionais
- R√°pido para detec√ß√£o online

**Local Outlier Factor (LOF)**
- Detecta anomalias com base em densidade local
- Melhor para agrupamentos n√£o esf√©ricos
- Sens√≠vel a mudan√ßas de densidade

**Ensemble**
- Combina ambos algoritmos com vota√ß√£o ponderada
- Threshold de confian√ßa configur√°vel (default: 0.5)
- Score final normalizado (0-1)

```python
from src.ml.anomaly_detector import create_anomaly_detector

detector = create_anomaly_detector(contamination=0.1)
detector.fit(historical_data)

predictions, scores = detector.detect_ensemble(new_data)
summary = detector.get_anomaly_summary(data)
```

**M√©todos Principais:**
- `fit(data)` - Treina o detector
- `detect_isolation_forest(data)` - Detec√ß√£o IS
- `detect_lof(data)` - Detec√ß√£o LOF
- `detect_ensemble(data, threshold)` - Detec√ß√£o ensemble
- `calculate_anomaly_threshold(data, percentile)` - Calcula threshold adaptativo
- `get_anomaly_summary(data)` - Resumo estat√≠stico

**Par√¢metros:**
- `contamination` (float): Taxa esperada de anomalias (0.01 a 0.5)
- `threshold` (float): Threshold de confian√ßa ensemble (0.3 a 0.8)

---

#### 2. **Time Series Forecaster** (`src/ml/forecaster.py`)

Previs√µes baseadas em Facebook Prophet

**Caracter√≠sticas:**
- Detec√ß√£o autom√°tica de tend√™ncias
- Sazonalidade anual/semanal/di√°ria
- Changepoints autom√°ticos (mudan√ßas de tend√™ncia)
- Intervalos de confian√ßa ajust√°veis

```python
from src.ml.forecaster import create_forecaster

forecaster = create_forecaster(interval_width=0.95)
forecaster.fit(timestamps, values)

forecast = forecaster.forecast(periods=24)  # Pr√≥ximas 24 horas
metrics = forecaster.calculate_metrics()
summary = forecaster.forecast_summary()
```

**M√©todos Principais:**
- `fit(timestamps, values)` - Treina o modelo
- `forecast(periods)` - Forecast de N per√≠odos
- `forecast_with_history(periods)` - Forecast + hist√≥rico
- `calculate_metrics()` - MAPE, RMSE, MAE
- `forecast_summary(periods)` - Resumo da previs√£o
- `get_components()` - Componentes do modelo

**Retorno do forecast:**
```python
{
    'timestamps': [datetime, ...],          # Timestamps previstos
    'forecasted_values': [float, ...],      # Valores previstos
    'lower_bound': [float, ...],            # Limite inferior (95%)
    'upper_bound': [float, ...],            # Limite superior (95%)
    'trend': [float, ...]                   # Componente de tend√™ncia
}
```

**M√©tricas:**
- **MAPE** (Mean Absolute Percentage Error): Erro percentual m√©dio
- **RMSE** (Root Mean Square Error): Raiz do erro quadr√°tico m√©dio
- **MAE** (Mean Absolute Error): Erro absoluto m√©dio

> Lower is better for all metrics

---

#### 3. **ML Engine** (`src/ml/ml_engine.py`)

Orquestrador central de opera√ß√µes ML

```python
from src.ml.ml_engine import create_ml_engine

engine = create_ml_engine()

# Detec√ß√£o de anomalias
anomaly_result = engine.detect_anomalies(sensor_id=1)
# {
#     'is_anomaly': bool,
#     'anomaly_score': float (0-1),
#     'value': float,
#     'historical_average': float,
#     'historical_std': float
# }

# Forecasting
forecast_result = engine.forecast_sensor(sensor_id=1, periods=24)
# {
#     'forecast': {...},
#     'metrics': {...},
#     'summary': {...}
# }

# Treino de modelos
engine.train_anomaly_detector(sensor_id=1, hours=168, contamination=0.1)
engine.train_forecaster(sensor_id=1, hours=72)

# Retrein todos os modelos
status = engine.retrain_all_models()

# Status dos modelos
status = engine.get_ml_status()
```

**M√©todos Principais:**
- `get_sensor_history(sensor_id, hours)` - Recupera hist√≥rico
- `train_anomaly_detector(sensor_id, hours, contamination)` - Treina AD
- `train_forecaster(sensor_id, hours)` - Treina forecaster
- `detect_anomalies(sensor_id)` - Detecta anomalias atuais
- `forecast_sensor(sensor_id, periods)` - Realiza forecast
- `save_prediction(...)` - Salva no DB
- `get_predictions(sensor_id, model_type, limit)` - Recupera predi√ß√µes
- `retrain_all_models()` - Retreina todos
- `get_ml_status()` - Status global

---

#### 4. **ML Repositories** (`src/ml/repositories.py`)

Camada de abstra√ß√£o para dados

**PredictionRepository**
- Opera√ß√µes CRUD em predi√ß√µes
- Busca por sensor, recentes, anomalias
- Estat√≠sticas de predi√ß√µes
- Limpeza de dados antigos

**SensorReadingsRepository**
- Acesso a leituras hist√≥ricas
- C√°lculo de estat√≠sticas
- Filtros por qualidade

**ModelTrainingRepository**
- Identifica sensores trein√°veis
- Verifica requisitos de dados

---

### Frontend

#### **Predictions Page** (`app/pages/predictions_page.py`)

Interface Streamlit com 4 abas:

##### 1. **Forecasting** üîÆ
- Sele√ß√£o de sensor e horizonte
- Visualiza√ß√£o de forecast com intervalo de confian√ßa
- M√©tricas de qualidade (MAPE, RMSE, MAE)
- Resumo da previs√£o (tend√™ncia, volatilidade)

##### 2. **Anomaly Detection** üö®
- Sele√ß√£o de sensor
- Status atual (Normal/Anomalia)
- Score de anomalia
- Gr√°fico hist√≥rico com anomalias destacadas
- Linhas de refer√™ncia (m√©dia, desvio padr√£o)

##### 3. **Model Status** üîß
- Cobertura de modelos treinados
- Detalhes por sensor:
  - Sensor name
  - Plataforma
  - Tipo
  - Status do anomaly detector
  - Status do forecaster

##### 4. **Training** üéØ
- Sele√ß√£o de sensores para treino
- Bot√£o de treino com progresso
- Requisitos de dados
- Dicas de melhoria

---

## üö® Anomaly Detection

### Como Funciona

1. **Treino (Off-line)**
   - Coleta dados hist√≥ricos (72 horas padr√£o)
   - Treina Isolation Forest + LOF com dados limpos
   - Calcula scores de normalidade

2. **Detec√ß√£o (Online)**
   - Novos dados s√£o passados para ambos modelos
   - Cada modelo gera predi√ß√£o (-1=anomalia, 1=normal)
   - Scores s√£o normalizados e combinados
   - Resultado final: predi√ß√£o + score (0-1)

### Interpreta√ß√£o de Scores

| Score | Interpreta√ß√£o | A√ß√£o |
|-------|---------------|------|
| 0.0-0.3 | Muito Normal | Nenhuma |
| 0.3-0.6 | Potencial Anomalia | Investigar |
| 0.6-0.9 | Prov√°vel Anomalia | Alerta |
| 0.9-1.0 | Certamente Anomalia | Cr√≠tico |

### Requisitos de Dados

- **M√≠nimo:** 30 amostras
- **Ideal:** 168+ amostras (7 dias)
- **Qualidade:** data_quality = 0 apenas

### Configura√ß√£o

```python
detector = create_anomaly_detector(contamination=0.1)
```

**Contamination:** Taxa esperada de anomalias
- 0.05 = 5% esperado como anomalia
- 0.10 = 10% esperado como anomalia
- Usar valores baixos (0.05-0.15) em geral

### Exemplo

```python
from src.ml.ml_engine import create_ml_engine

engine = create_ml_engine()

# Detectar anomalias
result = engine.detect_anomalies(sensor_id=1)

if result['is_anomaly']:
    print(f"üö® ANOMALIA DETECTADA!")
    print(f"Score: {result['anomaly_score']:.4f}")
    print(f"Valor: {result['value']:.2f}")
    print(f"M√©dia Hist√≥rica: {result['historical_average']:.2f}")
```

---

## üîÆ Time Series Forecasting

### Como Funciona

1. **Prepara√ß√£o**
   - S√©ries temporais s√£o convertidas para formato Prophet
   - Duplicatas s√£o removidas
   - Dados s√£o ordenados por timestamp

2. **Treino**
   - Prophet treina modelo com detec√ß√£o autom√°tica de:
     - Tend√™ncias (trend)
     - Sazonalidade anual (yearly)
     - Sazonalidade semanal (weekly)
     - Changepoints (mudan√ßas abruptas)

3. **Forecast**
   - Propaga componentes para futuro
   - Gera intervalos de confian√ßa (95% padr√£o)
   - Retorna trend e forecasted values

4. **M√©tricas**
   - Valida√ß√£o cruzada nos √∫ltimos 10% dos dados
   - Calcula MAPE, RMSE, MAE

### Interpreta√ß√£o de M√©tricas

| M√©trica | Boa | Aceit√°vel | Ruim |
|---------|-----|-----------|------|
| MAPE | < 10% | 10-20% | > 20% |
| RMSE | < 5 | 5-15 | > 15 |
| MAE | < 3 | 3-10 | > 10 |

> Valores dependem da escala dos dados

### Requisitos de Dados

- **M√≠nimo:** 50 amostras
- **Ideal:** 500+ amostras (para sazonalidade)
- **Frequ√™ncia:** Preferir dados regularmente espa√ßados
- **Qualidade:** data_quality = 0 apenas

### Configura√ß√£o

```python
forecaster = create_forecaster(
    interval_width=0.95,           # 95% confidence
    yearly_seasonality=True,        # Sazonalidade anual
    weekly_seasonality=True,        # Sazonalidade semanal
    daily_seasonality=False         # Sazonalidade di√°ria
)
```

### Exemplo

```python
from src.ml.ml_engine import create_ml_engine

engine = create_ml_engine()

# Forecast para 24 horas
result = engine.forecast_sensor(sensor_id=1, periods=24)

forecast = result['forecast']
metrics = result['metrics']
summary = result['summary']

print(f"Tend√™ncia: {summary['trend_direction']}")
print(f"Volatilidade: {summary['volatility']:.2f}")
print(f"MAPE: {metrics['mape']:.2f}%")
print(f"RMSE: {metrics['rmse']:.4f}")
```

---

## üîß ML Engine

### Fluxo de Opera√ß√£o

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           ML Engine Start                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ               ‚îÇ
    Anomaly          Forecast
    Detector         Timeseries
         ‚îÇ               ‚îÇ
         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
         ‚îÇ       ‚îÇ       ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îê
    ‚îÇ Train ‚îÇ ‚îÇTest ‚îÇ ‚îÇSave ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò
         ‚îÇ       ‚îÇ       ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  Results ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Lifecycle de um Modelo

1. **Treino** (Training)
   - Coleta dados hist√≥ricos
   - Treina modelo
   - Persiste em mem√≥ria (n√£o em arquivo)

2. **Infer√™ncia** (Inference)
   - Recebe novos dados
   - Aplica modelo
   - Retorna predi√ß√µes

3. **Valida√ß√£o** (Validation)
   - Valida qualidade via m√©tricas
   - Monitora performance

4. **Retreino** (Retraining)
   - Periodicamente (daily/weekly)
   - Usa novos dados coletados
   - Atualiza modelos

### Persist√™ncia de Predi√ß√µes

As predi√ß√µes s√£o salvas em `ml_predictions` :

```python
engine.save_prediction(
    sensor_id=1,
    model_type='FORECASTER',
    prediction_timestamp=datetime.now(),
    forecasted_value=55.2,
    confidence_low=51.0,
    confidence_high=59.4,
)
```

### Recupera√ß√£o de Predi√ß√µes

```python
predictions = engine.get_predictions(
    sensor_id=1,
    model_type='FORECASTER',
    limit=100
)
```

---

## üíª Interface Streamlit

### Acessar

1. Abrir Dashboard: `streamlit run app/main.py`
2. Navegar para: **Predictions**

### Workflows

#### Workflow 1: Visualizar Forecast

```
1. Ir para "Forecasting" tab
2. Selecionar sensor
3. Ajustar horizonte (hours)
4. Visualizar chart com intervalo de confian√ßa
5. Verificar m√©tricas (MAPE, RMSE, MAE)
```

#### Workflow 2: Detectar Anomalias

```
1. Ir para "Anomaly Detection" tab
2. Selecionar sensor
3. Ver status (Normal/Anomalia)
4. Ver score de anomalia
5. Ver hist√≥rico com anomalias destacadas
```

#### Workflow 3: Treinar Modelos

```
1. Ir para "Training" tab
2. Selecionar sensores
3. Clicar "Treinar Modelos"
4. Aguardar progresso
5. Ver resultado (quantos treinados)
```

#### Workflow 4: Monitorar Status

```
1. Ir para "Model Status" tab
2. Ver cobertura global
3. Ver detalhes por sensor
4. Identificar sensors sem modelos
```

---

## üéØ Uso e Exemplos

### Exemplo 1: Monitorar Anomalias em Tempo Real

```python
from src.ml.ml_engine import create_ml_engine
from src.sensors.sensor_manager import create_sensor_manager
import time

engine = create_ml_engine()
sensor_mgr = create_sensor_manager()

sensors = sensor_mgr.get_enabled_sensors()

while True:
    for sensor in sensors:
        result = engine.detect_anomalies(sensor.sensor_id)
        
        if result.get('is_anomaly'):
            print(f"‚ö†Ô∏è Anomalia em {sensor.display_name}")
            print(f"   Score: {result['anomaly_score']:.4f}")
            
            # Salvar predi√ß√£o
            engine.save_prediction(
                sensor_id=sensor.sensor_id,
                model_type='ANOMALY_DETECTOR',
                prediction_timestamp=result['timestamp'],
                anomaly_score=result['anomaly_score'],
                is_anomaly=True
            )
    
    time.sleep(60)  # Verificar a cada minuto
```

### Exemplo 2: Forecasting com Alertas

```python
from src.ml.ml_engine import create_ml_engine
from src.alerting.alert_engine import create_alert_engine

ml_engine = create_ml_engine()
alert_engine = create_alert_engine()

# Forecast para pr√≥ximas 24 horas
result = ml_engine.forecast_sensor(sensor_id=1, periods=24)
forecast = result['forecast']

# Verificar se forecast ultrapassa limites
max_forecasted = max(forecast['forecasted_values'])
threshold = 100.0

if max_forecasted > threshold:
    print(f"‚ö†Ô∏è Forecast prev√™ ultrapassar {threshold}")
    print(f"   M√°ximo: {max_forecasted:.2f}")
    
    # Criar alerta proativo
    alert_engine.create_alert(
        sensor_id=1,
        severity_level=2,  # Warning
        notes=f"Forecast: {max_forecasted:.2f} > {threshold}"
    )
```

### Exemplo 3: Retrein Autom√°tico

```python
from src.ml.ml_engine import create_ml_engine
from apscheduler.schedulers.background import BackgroundScheduler

engine = create_ml_engine()

def retrain_daily():
    """Retreina todos os modelos diariamente"""
    print("üîÑ Iniciando retrein...")
    result = engine.retrain_all_models()
    print(f"‚úì Retrein conclu√≠do: {result}")

# Agendar para todos os dias √†s 02:00 AM
scheduler = BackgroundScheduler()
scheduler.add_job(
    retrain_daily,
    'cron',
    hour=2,
    minute=0
)
scheduler.start()
```

---

## üß™ Testes

### Executar Testes

```bash
# Todos os testes ML
python -m pytest tests/unit/test_ml.py -v

# Teste espec√≠fico
python -m pytest tests/unit/test_ml.py::TestAnomalyDetector::test_isolation_forest_detection -v

# Com cobertura
python -m pytest tests/unit/test_ml.py --cov=src/ml --cov-report=html
```

### Cobertura de Testes

| Componente | Cobertura | Status |
|------------|-----------|--------|
| AnomalyDetector | 90%+ | ‚úì |
| TimeSeriesForecaster | 85%+ | ‚úì |
| MLEngine | 80%+ | ‚úì |

### Casos Testados

**AnomalyDetector:**
- Inicializa√ß√£o
- Treino
- Detec√ß√£o (IF, LOF, Ensemble)
- Calque de threshold
- Resumos
- Casos extremos (dados pequenos, valores constantes)

**TimeSeriesForecaster:**
- Inicializa√ß√£o
- Prepara√ß√£o de dados
- Treino
- Forecast
- M√©tricas
- Forecast com hist√≥rico

### Exemplo de Teste

```python
import pytest
from src.ml.anomaly_detector import create_anomaly_detector
import numpy as np

def test_anomaly_detection():
    # Setup
    detector = create_anomaly_detector(contamination=0.1)
    data = np.random.normal(50, 5, 100)
    
    # Execute
    detector.fit(data)
    predictions, scores = detector.detect_ensemble(data)
    
    # Assert
    assert len(predictions) == len(data)
    assert all(p in [-1, 1] for p in predictions)
```

---

## üìä Integra√ß√£o com Alert Engine

Os resultados de ML podem disparar alertas:

### Anomaly Detection ‚Üí Alerts

```python
# No alerting engine
if anomaly_result['is_anomaly'] and anomaly_result['anomaly_score'] > 0.8:
    alert_engine.create_alert(
        sensor_id=sensor_id,
        severity_level=3,  # Danger
        alert_type='ANOMALY',
        notes=f"Anomaly score: {anomaly_result['anomaly_score']:.4f}"
    )
```

### Forecasting ‚Üí Proactive Alerts

```python
# Alerta proativo antes de limite ser atingido
forecast_data = ml_engine.forecast_sensor(sensor_id, periods=24)
max_forecast = max(forecast_data['forecast']['forecasted_values'])

if max_forecast > upper_critical_limit:
    alert_engine.create_alert(
        sensor_id=sensor_id,
        severity_level=4,  # Critical
        alert_type='FORECAST_WARNING',
        notes=f"Forecast predicts critical level: {max_forecast:.2f}"
    )
```

---

## üêõ Troubleshooting

### Problema: "Dados insuficientes"

**Causa:** Menos de 30 amostras para anomaly detector ou 50 para forecaster

**Solu√ß√£o:**
1. Verificar sensor est√° coletando dados
2. Aguardar mais dados serem coletados
3. Verificar data_quality dos dados (deve ser 0)

```sql
-- Verificar dados
SELECT COUNT(*), data_quality 
FROM sensor_readings 
WHERE sensor_id = 1 
GROUP BY data_quality;
```

### Problema: MAPE/RMSE muito alto

**Causa:** Dados com muita variabilidade ou modelos n√£o treinados adequadamente

**Solu√ß√£o:**
1. Coletar mais dados hist√≥ricos
2. Verificar se h√° mudan√ßas abruptas (changepoints)
3. Retreinar modelo

### Problema: Muitas falsos-positivos em anomalias

**Causa:** Contamination rate muito alto ou dados ruim

**Solu√ß√£o:**
```python
# Reduzir contamination
detector = create_anomaly_detector(contamination=0.05)

# Ou usar threshold maior
predictions, scores = detector.detect_ensemble(
    data,
    threshold=0.7  # Aumentar de 0.5
)
```

### Problema: Modelos n√£o persistem

**Causa:** Modelos s√£o armazenados em mem√≥ria, perdidos ao restart

**Solu√ß√£o:**
Treinar novamente ap√≥s restart:
```python
engine.retrain_all_models()
```

Ou agendador para retrein autom√°tico di√°rio.

### Problema: Memory leak

**Causa:** Muitos sensores com modelos pesados

**Solu√ß√£o:**
1. Limitar numero de sensores
2. Fazer cleanup periodicamente
3. Usar garbage collection

```python
import gc
engine.retrain_all_models()
gc.collect()  # Limpar mem√≥ria
```

---

## üìà Performance & Escalabilidade

### Benchmark (Laptop t√≠pico)

| Opera√ß√£o | Tempo | Sensores |
|----------|-------|----------|
| Treinar AD | 500ms | 100 |
| Detectar anomalia | 10ms | Instant |
| Treinar Forecaster | 2s | 100 |
| Fazer forecast | 50ms | Instant |
| Retrein todos (100 sensors) | 3min | Autom√°tico |

### Otimiza√ß√µes

1. **Cache de modelos** em mem√≥ria
2. **Lazy loading** de dados hist√≥ricos
3. **Batch processing** para m√∫ltiplos sensores
4. **√çndices no banco de dados** para sensor_id, timestamps

### Escalabilidade

- **Atual:** 100-500 sens em laptop
- **Otimizado:** 1000+ sensores em servidor
- **Enterprise:** Usar PostgreSQL + Redis cache

---

## üöÄ Pr√≥ximos Passos

### Fase 4 (Advanced UI & Reporting)
- Dashboard em tempo real com WebSockets
- Relat√≥rios PDF/Excel com predi√ß√µes
- Export de modelos para deployment

### Fase 5 (Scheduling & Automation)
- Scheduler para retrein autom√°tico (daily)
- Alertas autom√°ticos baseados em forecasts
- Integra√ß√£o com alertas do Teams

### Futuro
- MLOps (Model versioning, experiment tracking)
- AutoML para otimiza√ß√£o de hyperparameters
- Deep Learning (LSTM, Transformer) para s√©ries longas
- Detec√ß√£o de drift de dados

---

## üìö Refer√™ncias

- [Prophet Documentation](https://facebook.github.io/prophet/)
- [Scikit-learn Anomaly Detection](https://scikit-learn.org/stable/modules/outlier_detection.html)
- [Isolation Forest Paper](https://ieeexplore.ieee.org/document/5356536)
- [Local Outlier Factor](https://en.wikipedia.org/wiki/Local_outlier_factor)

---

**Contato:** Gabriel Motta (info.motta@gmail.com)

**Licen√ßa:** Proprietary - Petrobras

---

*Documenta√ß√£o atualizada em: 2026-02-20 16:00 UTC*
